{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import random\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = pd.read_csv('data/preprocessed_train.csv')\n",
    "VAL = pd.read_csv('data/preprocessed_val.csv')\n",
    "TEST = pd.read_csv('data/preprocessed_test.csv')\n",
    "\n",
    "TRAIN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = list(TRAIN.columns[:-1])\n",
    "COLUMNS[2] = \"fam_hist\"\n",
    "COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_MAPPING = {\n",
    "    0: \"Normal\",\n",
    "    1: \"Obesity I\",\n",
    "    2: \"Obesity II\",\n",
    "    3: \"Obesity III\",\n",
    "    4: \"Overweight I\",\n",
    "    5: \"Overweight II\",\n",
    "    6: \"Underweight\"\n",
    "}\n",
    "\n",
    "Gender_MAPPPING = {\n",
    "    0: \"Female\",\n",
    "    1: \"Male\"\n",
    "}\n",
    "\n",
    "fam_hist_MAPPING = {\n",
    "    0: \"No\",\n",
    "    1: \"Yes\"\n",
    "}\n",
    "\n",
    "FAVC_MAPPING = {\n",
    "    0: \"No\",\n",
    "    1: \"Yes\"\n",
    "}\n",
    "\n",
    "CAEC_MAPPING = {\n",
    "    0: \"Always\",\n",
    "    1: \"Frequently\",\n",
    "    2: \"Sometimes\",\n",
    "    3: \"No\"\n",
    "}\n",
    "\n",
    "SMOKE_MAPPING = {\n",
    "    0: \"No\",\n",
    "    1: \"Yes\"\n",
    "}\n",
    "\n",
    "SCC_MAPPING = {\n",
    "    0: \"No\",\n",
    "    1: \"Yes\"\n",
    "}\n",
    "\n",
    "CALC_MAPPING = {\n",
    "    0: \"Frequently\",\n",
    "    1: \"Sometimes\",\n",
    "    2: \"No\"\n",
    "}\n",
    "\n",
    "MTRANS_MAPPING = {\n",
    "    0: \"Automobile\",\n",
    "    1: \"Bike\",\n",
    "    2: \"Motorbike\",\n",
    "    3: \"Public_Transportation\",\n",
    "    4: \"Walking\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoGaussianMixturePrior:\n",
    "    def __init__(\n",
    "        self, \n",
    "        sigma_1: float = 1, \n",
    "        sigma_2: float = 1e-6, \n",
    "        mixing: float = 0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mixing = mixing\n",
    "        \n",
    "        self.w_prior_1 = torch.distributions.Normal(0, sigma_1)\n",
    "        self.w_prior_2 = torch.distributions.Normal(0, sigma_2)\n",
    "        \n",
    "        self.b_prior_1 = torch.distributions.Normal(0, sigma_1)\n",
    "        self.b_prior_2 = torch.distributions.Normal(0, sigma_2)\n",
    "        \n",
    "    def log_prob(self, weights: torch.Tensor, biases: torch.Tensor):\n",
    "        w_log_prior_1 = self.w_prior_1.log_prob(weights).exp()\n",
    "        w_log_prior_2 = self.w_prior_2.log_prob(weights).exp()\n",
    "        \n",
    "        w_prior = self.mixing * w_log_prior_1 + (1 - self.mixing) * w_log_prior_2\n",
    "        \n",
    "        b_log_prior_1 = self.b_prior_1.log_prob(biases).exp()\n",
    "        b_log_prior_2 = self.b_prior_2.log_prob(biases).exp()\n",
    "        \n",
    "        b_prior = self.mixing * b_log_prior_1 + (1 - self.mixing) * b_log_prior_2\n",
    "    \n",
    "        return w_prior.log().mean() + b_prior.log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianLinear(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_input_features: int,\n",
    "        num_output_features: int,\n",
    "        prior: TwoGaussianMixturePrior,\n",
    "    ):\n",
    "        \"\"\"Implement initialization of weights and biases values\"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.prior = prior\n",
    "        \n",
    "        self.last_weights_ = None\n",
    "        self.last_biases_ = None\n",
    "        \n",
    "        # Define weights parameters and initialize them using uniform distribution\n",
    "        self.weights_mean = nn.Parameter(torch.empty(num_input_features, num_output_features))\n",
    "        self.weights_std = nn.Parameter(torch.empty(num_input_features, num_output_features))\n",
    "        nn.init.uniform_(self.weights_mean, a=-0.5, b=0.5)\n",
    "        nn.init.uniform_(self.weights_std, a=-5, b=-3)\n",
    "        \n",
    "        # Define biases parameters and initialize them using uniform distribution\n",
    "        self.biases_mean = nn.Parameter(torch.empty(num_output_features))\n",
    "        self.biases_std = nn.Parameter(torch.empty(num_output_features))\n",
    "        nn.init.uniform_(self.biases_mean)\n",
    "        nn.init.uniform_(self.biases_std)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Implement forward inference using reparametrization trick\"\"\"\n",
    "        \n",
    "        weights = None\n",
    "        biases = None\n",
    "        \n",
    "        eps_weights = torch.normal(torch.zeros(self.weights_mean.shape), torch.ones(self.weights_mean.shape))\n",
    "        eps_biases = torch.normal(torch.zeros(self.biases_mean.shape), torch.ones(self.biases_mean.shape))\n",
    "\n",
    "        weights = self.weights_mean + torch.log(1 + torch.exp(self.weights_std)) * eps_weights\n",
    "        biases = self.biases_mean + torch.log(1 + torch.exp(self.biases_std)) * eps_biases\n",
    "        \n",
    "        self.last_weights_ = weights\n",
    "        self.last_biases_ = biases\n",
    "\n",
    "        return x @ weights + biases\n",
    "        \n",
    "    def prior_log_prob(self) -> torch.Tensor:\n",
    "        \"\"\"Calculates the prior log prob of sampled weights and biases.\"\"\"\n",
    "        return self.prior.log_prob(weights=self.last_weights_, biases=self.last_biases_)\n",
    "        \n",
    "    def variational_log_prob(self) -> torch.Tensor:\n",
    "        \"\"\"Implement the variational log prob.\"\"\"\n",
    "        weights_std = torch.log(1 + torch.exp(self.weights_std))\n",
    "        biases_std = torch.log(1 + torch.exp(self.biases_std))\n",
    "\n",
    "        w_posterior = torch.distributions.Normal(self.weights_mean, weights_std)\n",
    "        b_posterior = torch.distributions.Normal(self.biases_mean, biases_std)\n",
    "        \n",
    "        return w_posterior.log_prob(self.last_weights_).mean() + b_posterior.log_prob(self.last_biases_).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianMLP(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_input_features: int,\n",
    "        num_hidden_features: int,\n",
    "        num_output_classes: int,\n",
    "        prior: TwoGaussianMixturePrior,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer_1 = BayesianLinear(\n",
    "            num_input_features, num_hidden_features, \n",
    "            prior=prior,\n",
    "        )\n",
    "        self.layer_2 = BayesianLinear(\n",
    "            num_hidden_features, num_output_classes, \n",
    "            prior=prior,\n",
    "        )\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, use_softmax=True) -> torch.Tensor:\n",
    "        x = self.sigmoid(self.layer_1(x))\n",
    "        x = self.layer_2(x)\n",
    "        if use_softmax:\n",
    "            x = self.softmax(x)\n",
    "        return x\n",
    "        \n",
    "    def prior_log_prob(self) -> torch.Tensor:\n",
    "        log_prob = 0\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, BayesianLinear):\n",
    "                log_prob += module.prior_log_prob()\n",
    "        return log_prob\n",
    "        \n",
    "    def variational_log_prob(self) -> torch.Tensor:\n",
    "        log_prob = 0\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, BayesianLinear):\n",
    "                log_prob += module.variational_log_prob()\n",
    "        return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Tuple\n",
    "\n",
    "class ELBO(nn.Module):\n",
    "    def __init__(self, N: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.N = N\n",
    "        self.nll = nn.NLLLoss(reduction=\"none\")\n",
    "        \n",
    "    def forward(\n",
    "        self, \n",
    "        model: nn.Module, \n",
    "        inputs: torch.Tensor,\n",
    "        targets: torch.Tensor,\n",
    "        *,\n",
    "        return_predictions: bool = False,\n",
    "    ) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        predictions = []\n",
    "        log_posteriors = []\n",
    "        log_priors = []\n",
    "        \n",
    "        for _ in range(self.N):\n",
    "            preds = model(inputs)\n",
    "            log_priors.append(model.prior_log_prob())\n",
    "            log_posteriors.append(model.variational_log_prob())\n",
    "            # NLLLoss input is log probabilities\n",
    "            predictions.append(preds)\n",
    "            \n",
    "        loss = 0\n",
    "\n",
    "        sum_log_posterior = sum(log_posteriors)\n",
    "        sum_log_prior = sum(log_priors)\n",
    "\n",
    "        sum_loss_nll = 0\n",
    "        for pred in predictions:\n",
    "            sum_loss_nll += torch.sum(self.nll(pred.log(), targets))\n",
    "        \n",
    "        # loss_nll is negative that's why we need to add it\n",
    "        loss = (sum_log_posterior - sum_log_prior + sum_loss_nll) / self.N\n",
    "        \n",
    "        if return_predictions:\n",
    "            return loss, torch.stack(predictions, dim=-1)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.tensor(data.values).float()\n",
    "        self.labels = torch.tensor(labels).long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOAT_EPS = torch.finfo(torch.float32).eps\n",
    "\n",
    "class Analyzer:\n",
    "    def __init__(self, model: nn.Module, dataset: Dataset, num_samplings: int):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.num_samplings = num_samplings\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        self._preds: Optional[torch.Tensor] = None\n",
    "        self._trues: Optional[torch.Tensor] = None\n",
    "        self._data: Optional[torch.Tensor] = None\n",
    "\n",
    "        self._retrieve_predictions()\n",
    "\n",
    "    def reset_state(self):\n",
    "        self._preds = None\n",
    "        self._trues = None\n",
    "\n",
    "    def _retrieve_predictions(self):\n",
    "        loader = DataLoader(\n",
    "            self.dataset, batch_size=32, shuffle=False, drop_last=False\n",
    "        )\n",
    "\n",
    "        trues = []\n",
    "        preds = []\n",
    "        data = []\n",
    "        for inputs, targets in loader:\n",
    "            data.append(inputs)\n",
    "            trues.append(targets)\n",
    "            if self.num_samplings <= 1:\n",
    "                preds.append(self.model(inputs).detach())\n",
    "            else:\n",
    "                loc_preds = []\n",
    "                for _ in range(self.num_samplings):\n",
    "                    loc_preds.append(self.model(inputs).detach())\n",
    "                preds.append(torch.stack(loc_preds, dim=-1))\n",
    "\n",
    "        self._preds = torch.cat(preds, dim=0)\n",
    "        self._trues = torch.cat(trues, dim=0)\n",
    "        self._data = torch.cat(data, dim=0)\n",
    "\n",
    "    @classmethod\n",
    "    def _get_entropy(cls, matrix: torch.Tensor) -> torch.Tensor:\n",
    "        return -(matrix * matrix.clamp_min(FLOAT_EPS).log()).sum(dim=-1)\n",
    "\n",
    "    def get_top_k_high_confidence_mistakes(\n",
    "        self, k: int = 10\n",
    "    ) -> Tuple[torch.Tensor, ...]:\n",
    "        \n",
    "        if len(self._preds.shape) == 3:\n",
    "            mean_preds = self._preds.mean(dim=-1)\n",
    "        else:\n",
    "            mean_preds = self._preds\n",
    "            \n",
    "        where_mistakes = mean_preds.argmax(dim=-1) != self._trues\n",
    "        preds_with_mistakes = mean_preds[where_mistakes]\n",
    "        data = self._data[where_mistakes]\n",
    "        trues = self._trues[where_mistakes]\n",
    "\n",
    "        top_high_confidence_indices = self._get_entropy(\n",
    "            preds_with_mistakes\n",
    "        ).argsort(descending=False)[:k]\n",
    "        \n",
    "        return (\n",
    "            data[top_high_confidence_indices],\n",
    "            self._preds[where_mistakes][top_high_confidence_indices],\n",
    "            trues[top_high_confidence_indices],\n",
    "        )\n",
    "\n",
    "    def get_top_k_low_confidence_mistakes(\n",
    "        self, k: int = 10\n",
    "    ) -> Tuple[torch.Tensor, ...]:\n",
    "        \n",
    "        if len(self._preds.shape) == 3:\n",
    "            mean_preds = self._preds.mean(dim=-1)\n",
    "        else:\n",
    "            mean_preds = self._preds\n",
    "            \n",
    "        where_mistakes = mean_preds.argmax(dim=-1) != self._trues\n",
    "        preds_with_mistakes = mean_preds[where_mistakes]\n",
    "        data = self._data[where_mistakes]\n",
    "        trues = self._trues[where_mistakes]\n",
    "\n",
    "        top_low_confidence_indices = self._get_entropy(\n",
    "            preds_with_mistakes\n",
    "        ).argsort(descending=True)[:k]\n",
    "        \n",
    "        return (\n",
    "            data[top_low_confidence_indices],\n",
    "            self._preds[where_mistakes][top_low_confidence_indices],\n",
    "            trues[top_low_confidence_indices],\n",
    "        )\n",
    "\n",
    "    def get_top_k_high_confidence_correct(\n",
    "        self, k: int = 10\n",
    "    ) -> Tuple[torch.Tensor, ...]:\n",
    "        \n",
    "        if len(self._preds.shape) == 3:\n",
    "            mean_preds = self._preds.mean(dim=-1)\n",
    "        else:\n",
    "            mean_preds = self._preds\n",
    "            \n",
    "        where_correct = mean_preds.argmax(dim=-1) == self._trues\n",
    "        preds_correct = mean_preds[where_correct]\n",
    "        data = self._data[where_correct]\n",
    "        trues = self._trues[where_correct]\n",
    "\n",
    "        top_high_confidence_indices = self._get_entropy(\n",
    "            preds_correct\n",
    "        ).argsort(descending=False)[:k]\n",
    "        \n",
    "        return (\n",
    "            data[top_high_confidence_indices],\n",
    "            self._preds[where_correct][top_high_confidence_indices],\n",
    "            trues[top_high_confidence_indices],\n",
    "        )\n",
    "\n",
    "    def get_top_k_low_confidence_correct(\n",
    "        self, k: int = 10\n",
    "    ) -> Tuple[torch.Tensor, ...]:\n",
    "        \n",
    "        if len(self._preds.shape) == 3:\n",
    "            mean_preds = self._preds.mean(dim=-1)\n",
    "        else:\n",
    "            mean_preds = self._preds\n",
    "            \n",
    "        where_correct = mean_preds.argmax(dim=-1) == self._trues\n",
    "        preds_correct = mean_preds[where_correct]\n",
    "        data = self._data[where_correct]\n",
    "        trues = self._trues[where_correct]\n",
    "\n",
    "        top_low_confidence_indices = self._get_entropy(\n",
    "            preds_correct\n",
    "        ).argsort(descending=True)[:k]\n",
    "        \n",
    "        return (\n",
    "            data[top_low_confidence_indices],\n",
    "            self._preds[where_correct][top_low_confidence_indices],\n",
    "            trues[top_low_confidence_indices],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_weights(params: torch.Tensor, name: str) -> plt.Figure:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    sns.kdeplot(params.view((-1,)).detach().numpy(), ax=ax)\n",
    "    ax.set_title(f\"Kernel density plot of {name}\")\n",
    "    return fig\n",
    "\n",
    "\n",
    "def show_learning_curve(\n",
    "    train_metrics: Dict[str, List[float]], test_metrics: Dict[str, List[float]]\n",
    ") -> plt.Figure:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    ax.plot(train_metrics[\"step\"], train_metrics[\"loss\"], label=\"train\")\n",
    "    ax.plot(test_metrics[\"step\"], test_metrics[\"loss\"], label=\"test\")\n",
    "    ax.set_xlabel(\"Training step\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_title(\"Learning curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_accuracy_curve(\n",
    "    train_metrics: Dict[str, List[float]], test_metrics: Dict[str, List[float]]\n",
    ") -> plt.Figure:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    plt.plot(train_metrics[\"step\"], train_metrics[\"acc\"], label=\"train\")\n",
    "    ax.plot(test_metrics[\"step\"], test_metrics[\"acc\"], label=\"test\")\n",
    "    ax.set_xlabel(\"Training step\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_title(\"Accuracy curve\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tensor_to_text(info_tensor):\n",
    "    text_to_display = \"\"\n",
    "    for info, col_name in zip(info_tensor, COLUMNS):\n",
    "        if col_name == \"Gender\":\n",
    "            text = Gender_MAPPPING[int(info.item())]\n",
    "        elif col_name == \"fam_hist\":\n",
    "            text = fam_hist_MAPPING[int(info.item())]\n",
    "        elif col_name == \"FAVC\":\n",
    "            text = FAVC_MAPPING[int(info.item())]\n",
    "        elif col_name == \"CAEC\":\n",
    "            text = CAEC_MAPPING[int(info.item())]\n",
    "        elif col_name == \"SMOKE\":\n",
    "            text = SMOKE_MAPPING[int(info.item())]\n",
    "        elif col_name == \"SCC\":\n",
    "            text = SCC_MAPPING[int(info.item())]\n",
    "        elif col_name == \"CALC\":\n",
    "            text = CALC_MAPPING[int(info.item())]\n",
    "        elif col_name == \"MTRANS\":\n",
    "            text = MTRANS_MAPPING[int(info.item())]\n",
    "        else:\n",
    "            text = f'{info.item():.4f}'\n",
    "        \n",
    "        text_to_display = text_to_display + f'{col_name}:{text}\\n'\n",
    "        \n",
    "    return text_to_display\n",
    "\n",
    "def visualize_samples(\n",
    "    data: torch.Tensor,\n",
    "    preds: torch.Tensor,\n",
    "    trues: torch.Tensor,\n",
    "    num_cols: int = 10\n",
    ") -> None:\n",
    "\n",
    "    target_values = list(y_MAPPING.values())\n",
    "    no_target_values = len(target_values)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        1, num_cols, figsize=(3 * num_cols, 2 * 2)\n",
    "    )\n",
    "\n",
    "    is_with_multiple_samplings = len(preds.shape) == 3\n",
    "\n",
    "    x = 0\n",
    "    for info, pred, true in zip(\n",
    "        data, preds, trues\n",
    "    ):  # type: torch.Tensor, torch.Tensor, torch.Tensor\n",
    "        if is_with_multiple_samplings:\n",
    "            pred_mean = pred.mean(dim=-1)\n",
    "            pred_std = pred.std(dim=-1)\n",
    "        else:\n",
    "            pred_mean = pred\n",
    "            pred_std = 0\n",
    "\n",
    "        pred_class = pred_mean.argmax().item()\n",
    "        true_class = true.item()\n",
    "        axes[x].set_title(f\"Pred: {y_MAPPING[pred_class]} \\n True: {y_MAPPING[true_class]}\")\n",
    "        axes[x].bar(np.arange(no_target_values), pred_mean, yerr=pred_std)\n",
    "        axes[x].set_ylim(0, 1)\n",
    "\n",
    "        if pred_class == true_class:\n",
    "            axes[x].bar([pred_class], pred_mean[[pred_class]], color=\"green\")\n",
    "        else:\n",
    "            axes[x].bar([true_class], pred_mean[[true_class]], color=\"yellow\")\n",
    "            axes[x].bar([pred_class], pred_mean[[pred_class]], color=\"red\")\n",
    "\n",
    "        axes[x].set_xticks(range(len(target_values)))\n",
    "        axes[x].set_xticklabels(target_values)\n",
    "        axes[x].tick_params(axis='x', labelrotation=90)\n",
    "\n",
    "        \n",
    "        axes[x].text(0, -1.2, convert_tensor_to_text(info))\n",
    "        x += 1\n",
    "            \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=0):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "def fit_elbo(\n",
    "    model: nn.Module,\n",
    "    train_dataset: Dataset,\n",
    "    val_dataset: Dataset,\n",
    "    loss_fn: nn.Module,\n",
    "    batch_size: int,\n",
    "    epochs: int,\n",
    "    optimizer: Optimizer,\n",
    ") -> Tuple[Dict[str, List[float]], ...]:\n",
    "    train_metrics = {\"loss\": [], \"acc\": [], \"step\": []}\n",
    "    test_metrics = {\"loss\": [], \"acc\": [], \"step\": []}\n",
    "\n",
    "    global_step = 0\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, drop_last=False\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch: {epoch + 1} / {epochs}\")\n",
    "\n",
    "        # train step\n",
    "        model.train()\n",
    "        pbar = tqdm(train_loader)\n",
    "        for inputs, targets in pbar:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss, y_predictions = loss_fn(\n",
    "                model, inputs, targets, return_predictions=True\n",
    "            )\n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "            \n",
    "            y_predictions = y_predictions.mean(dim=-1)\n",
    "            \n",
    "            accuracy = (\n",
    "                (y_predictions.argmax(dim=1) == targets)\n",
    "                .float()\n",
    "                .mean()\n",
    "            )\n",
    "\n",
    "            train_metrics[\"loss\"].append(loss.item())\n",
    "            train_metrics[\"acc\"].append(accuracy.item())\n",
    "            train_metrics[\"step\"].append(global_step)\n",
    "            global_step += 1\n",
    "            pbar.update(1)\n",
    "            \n",
    "        pbar.close()\n",
    "\n",
    "        # validating step\n",
    "        model.eval()\n",
    "\n",
    "        preds = []\n",
    "        trues = []\n",
    "        total_batches = 0\n",
    "        total_loss = 0.0\n",
    "        for inputs, targets in val_loader:\n",
    "            loss, y_predictions = loss_fn(\n",
    "                model, inputs, targets, return_predictions=True\n",
    "            )\n",
    "            \n",
    "            y_predictions = y_predictions.mean(dim=-1)\n",
    "            total_batches += 1\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            trues.append(targets)\n",
    "            preds.append(y_predictions)\n",
    "\n",
    "        preds = torch.cat(preds, dim=0)\n",
    "        trues = torch.cat(trues, dim=0)\n",
    "\n",
    "        val_acc = (\n",
    "            (preds.argmax(dim=1) == trues).float().mean().item()\n",
    "        )\n",
    "\n",
    "        test_metrics[\"loss\"].append(total_loss / total_batches)\n",
    "        test_metrics[\"acc\"].append(val_acc)\n",
    "        test_metrics[\"step\"].append(global_step)\n",
    "\n",
    "    return train_metrics, test_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests - hyperparameters search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILS\n",
    "BATCH_SIZE = 32\n",
    "NO_EPOCHS = 30\n",
    "MODEL_NAME = \"model.pt\"\n",
    "TRAIN_CSV_NAME = \"train.csv\"\n",
    "VAL_CSV_NAME = \"val.csv\"\n",
    "\n",
    "def get_results(folder):\n",
    "    train_df = pd.read_csv(os.path.join(folder, TRAIN_CSV_NAME))\n",
    "    val_df = pd.read_csv(os.path.join(folder, VAL_CSV_NAME))\n",
    "\n",
    "    return (\n",
    "        min(train_df[\"loss\"]),\n",
    "        max(train_df[\"acc\"]), \n",
    "        min(val_df['loss']), \n",
    "        max(val_df['acc'])\n",
    "    )\n",
    "\n",
    "def get_model(folder):\n",
    "    return torch.load(os.path.join(folder, MODEL_NAME))\n",
    "\n",
    "def visualise_results(folder):\n",
    "    train_metrics = pd.read_csv(os.path.join(folder, TRAIN_CSV_NAME))\n",
    "    test_metrics = pd.read_csv(os.path.join(folder, VAL_CSV_NAME))\n",
    "    \n",
    "    show_learning_curve(train_metrics, test_metrics)\n",
    "    show_accuracy_curve(train_metrics, test_metrics)\n",
    "\n",
    "def calculate_metrics(model, X_test, y_test):\n",
    "    with torch.no_grad():\n",
    "        model_input = torch.tensor(X_test.values).float()\n",
    "        y_pred = model(model_input)\n",
    "\n",
    "    y_pred_argmax = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred_argmax)\n",
    "    prec = precision_score(y_test, y_pred_argmax, average='micro')\n",
    "    rec = recall_score(y_test, y_pred_argmax, average='micro')\n",
    "    f1 = f1_score(y_test, y_pred_argmax, average='micro')\n",
    "    roc = roc_auc_score(y_test, y_pred, average='micro', multi_class='ovr')\n",
    "\n",
    "    return {\n",
    "        \"Acccuracy\": accuracy,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1-Score\": f1,\n",
    "        \"ROC AUC Score\": roc\n",
    "    }\n",
    "\n",
    "def plot_credible_intervals(X_test, y_test, class_index, samples=100):\n",
    "    y_filter = y_test[y_test==class_index]\n",
    "    X_filter = X_test.iloc[y_filter.index]\n",
    "\n",
    "    X_tmp = torch.tensor(X_filter.values).float()\n",
    "    y_samp = np.zeros((samples, X_filter.shape[0]))\n",
    "    for s in range(samples):\n",
    "        y_tmp = best_model(X_tmp, use_softmax=False).detach().numpy()\n",
    "        y_samp[s] = y_tmp[:, class_index]\n",
    "\n",
    "    pca = PCA(1)\n",
    "    X_plot = pca.fit_transform(X_tmp).reshape(-1)\n",
    "    \n",
    "    X_plot = pd.Series(X_plot).sort_values()\n",
    "    y_samp = y_samp[X_plot.index]\n",
    "\n",
    "    plt.plot(X_plot, np.mean(y_samp, axis=0), label='Mean Posterior Predictive')\n",
    "    plt.fill_between(X_plot, np.percentile(y_samp, 5, axis = 0), np.percentile(y_samp, 95, axis = 0), alpha = 0.25, label='90% Confidence')\n",
    "    plt.title(f\"Confidence interval for class {y_MAPPING[class_index]}\")\n",
    "    plt.xlabel(\"X after PCA transform\")\n",
    "    plt.ylabel(\"Prediction (without softmax)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = TRAIN.drop(['y'], axis=1)\n",
    "y_train = TRAIN['y']\n",
    "X_val = VAL.drop(['y'], axis=1)\n",
    "y_val = VAL['y']\n",
    "X_test = TEST.drop(['y'], axis=1)\n",
    "y_test = TEST['y']\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "val_dataset = CustomDataset(X_val, y_val)\n",
    "test_dataset = CustomDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [1e-2, 1e-3, 1e-4]\n",
    "num_hidden_featuress = [64, 128, 256]\n",
    "sigma_1s = [0.5, 1]\n",
    "sigma_2s = [1e-6, 1e-3]\n",
    "mixings = [0.2, 0.5, 0.8, 1] # mixing set to 1 make Gausiann Mixture a Normal Distribution\n",
    "\n",
    "parameters = []\n",
    "folders = []\n",
    "os.makedirs(\"bayesian_neural_networks_models\", exist_ok=True)\n",
    "for lr in lrs:\n",
    "    for num_hidden_features in num_hidden_featuress:\n",
    "        for sigma_1 in sigma_1s:\n",
    "            for mixing in mixings:\n",
    "                for sigma_2 in sigma_2s:\n",
    "                    # If mixing is equal to 1 than sigma_2 value has no meaning\n",
    "                    if mixing == 1:\n",
    "                        sigma_2 = 1e-6\n",
    "                    \n",
    "                    file_name = f'{lr}{num_hidden_features}{sigma_1}{sigma_2}{mixing}'\n",
    "                    folder_name = os.path.join(\"bayesian_neural_networks_models\", file_name)\n",
    "\n",
    "                    if folder_name not in folders:\n",
    "                        parameters.append((lr, num_hidden_features, sigma_1, sigma_2, mixing))\n",
    "                        folders.append(folder_name)\n",
    "\n",
    "                    if not os.path.exists(folder_name):\n",
    "                        print(f'Training lr:{lr}, num_hidden_features:{num_hidden_features}, sigma_1:{sigma_1}, sigma_2:{sigma_2}, mixing:{mixing}')\n",
    "                        set_seed(0)\n",
    "    \n",
    "                        model = BayesianMLP(\n",
    "                            num_input_features=X_train.shape[1],\n",
    "                            num_hidden_features=num_hidden_features, \n",
    "                            num_output_classes=len(y_train.unique()),\n",
    "                            prior=TwoGaussianMixturePrior(sigma_1, sigma_2, mixing),\n",
    "                        )\n",
    "                        \n",
    "                        loss_fn = ELBO(N=10)\n",
    "                        optimizer = torch.optim.Adam(\n",
    "                            model.parameters(), \n",
    "                            lr=lr, \n",
    "                        )\n",
    "    \n",
    "                        train_metrics, test_metrics = fit_elbo(\n",
    "                            model=model,\n",
    "                            train_dataset=train_dataset,\n",
    "                            val_dataset=val_dataset,\n",
    "                            loss_fn=loss_fn,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            epochs=NO_EPOCHS,\n",
    "                            optimizer=optimizer,\n",
    "                        )\n",
    "\n",
    "                        os.makedirs(folder_name, exist_ok=True)\n",
    "    \n",
    "                        torch.save(model, os.path.join(folder_name, MODEL_NAME))\n",
    "    \n",
    "                        elements = np.array([\n",
    "                            train_metrics['loss'],\n",
    "                            train_metrics['acc'],\n",
    "                            train_metrics['step']\n",
    "                        ]).transpose(1, 0)\n",
    "    \n",
    "                        train_df = pd.DataFrame(elements, columns=[\"loss\", \"acc\", \"step\"])\n",
    "                        train_df.to_csv(os.path.join(folder_name, TRAIN_CSV_NAME))\n",
    "    \n",
    "                        elements = np.array([\n",
    "                            test_metrics['loss'],\n",
    "                            test_metrics['acc'],\n",
    "                            test_metrics['step']\n",
    "                        ]).transpose(1, 0)\n",
    "    \n",
    "                        val_df = pd.DataFrame(elements, columns=[\"loss\", \"acc\", \"step\"])\n",
    "                        val_df.to_csv(os.path.join(folder_name, VAL_CSV_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params = pd.DataFrame(parameters, columns=[\"lr\", \"num_hidden_features\", \"sigma_1\", \"sigma_2\", \"mixing\"])\n",
    "df_params.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = [get_results(f) for f in folders]\n",
    "df_results = pd.DataFrame(all_results, columns=[\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\"])\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_params, df_results, left_index=True, right_index=True)\n",
    "df['folder'] = folders\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df_sorted = df.sort_values('val_loss')\n",
    "df_sorted = df_sorted.reset_index(drop=True)\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests - analiza wynikÃ³w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['lr', 'train_loss', 'train_acc', 'val_loss', 'val_acc']].groupby(\"lr\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['num_hidden_features', 'train_loss', 'train_acc', 'val_loss', 'val_acc']].groupby(\"num_hidden_features\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['sigma_1', 'train_loss', 'train_acc', 'val_loss', 'val_acc']].groupby(\"sigma_1\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['mixing'] != 1][['sigma_2', 'train_loss', 'train_acc', 'val_loss', 'val_acc']].groupby(\"sigma_2\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['mixing', 'train_loss', 'train_acc', 'val_loss', 'val_acc']].groupby(\"mixing\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We choose the best model and analyse it\n",
    "best_model = get_model(df_sorted.iloc[0]['folder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_results(df_sorted.iloc[0]['folder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samplings = 10\n",
    "analyzer = Analyzer(best_model, test_dataset, num_samplings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top high confidence correct predictions\")\n",
    "visualize_samples(\n",
    "    *analyzer.get_top_k_high_confidence_correct(5),\n",
    "    num_cols=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top low confidence correct predictions\")\n",
    "visualize_samples(\n",
    "    *analyzer.get_top_k_low_confidence_correct(5),\n",
    "    num_cols=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top low confidence wrong predictions\")\n",
    "visualize_samples(\n",
    "    *analyzer.get_top_k_low_confidence_mistakes(5),\n",
    "    num_cols=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top high confidence wrong predictions\")\n",
    "visualize_samples(\n",
    "    *analyzer.get_top_k_high_confidence_mistakes(5),\n",
    "    num_cols=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_weights(best_model.layer_1.weights_mean, \"layer input -> hidden\")\n",
    "visualize_weights(best_model.layer_1.weights_std, \"layer hidden -> output (std)\")\n",
    "print(\"Histogram of weights for layer 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_weights(best_model.layer_1.biases_mean, \"layer input -> hidden\")\n",
    "visualize_weights(best_model.layer_1.biases_std, \"layer hidden -> output (std)\")\n",
    "print(\"Histogram of biases for layer 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_weights(best_model.layer_2.weights_mean, \"layer hidden -> output (mean)\")\n",
    "visualize_weights(best_model.layer_2.weights_std, \"layer hidden -> output (std)\")\n",
    "print(\"Histogram of weights for layer 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_weights(best_model.layer_2.biases_mean, \"layer input -> hidden\")\n",
    "visualize_weights(best_model.layer_2.biases_std, \"layer hidden -> output (std)\")\n",
    "print(\"Histogram of biases for layer 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credible intervals\n",
    "plot_credible_intervals(X_test, y_test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_credible_intervals(X_test, y_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_credible_intervals(X_test, y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_credible_intervals(X_test, y_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_credible_intervals(X_test, y_test, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_credible_intervals(X_test, y_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_credible_intervals(X_test, y_test, 6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
